{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab1ece7c-308b-4716-92a3-f45115967ef5",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results.\n",
    "\n",
    "ANOVA (Analysis of Variance) is a statistical method used to compare the means of three or more groups to determine whether they are significantly different. The following are the assumptions that need to be met for ANOVA to be valid:\n",
    "\n",
    "Independence: Observations in each group should be independent of each other. If observations are not independent, then the variance may be overestimated, leading to a false positive result.\n",
    "\n",
    "Normality: The data should be normally distributed within each group. Non-normality can cause the results to be inaccurate, which can lead to Type I or Type II errors.\n",
    "\n",
    "Homogeneity of variances: The variance within each group should be equal. If the variance is unequal, then the assumption of homogeneity of variances is violated, and the F-test used in ANOVA may not be accurate.\n",
    "\n",
    "If any of the assumptions are violated, the validity of the ANOVA results may be compromised. Here are some examples of violations that could impact the validity of the results:\n",
    "\n",
    "Violation of independence: This can occur when the observations in one group are related to the observations in another group. For example, in a study comparing the effectiveness of two different treatments for a condition, if some patients receive both treatments, then their observations may not be independent.\n",
    "\n",
    "Violation of normality: This can occur when the data is skewed or has outliers. For example, in a study comparing the heights of people from different regions, if there are a few extremely tall people in one group, then the data may not be normally distributed.\n",
    "\n",
    "Violation of homogeneity of variances: This can occur when the variance within groups is different. For example, in a study comparing the effectiveness of two different drugs on a disease, if one drug has a much larger effect than the other, then the variance within the groups may be different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7deb73c2-6ede-4d0f-a3c8-16ad6a60ea33",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?\n",
    "\n",
    "The three types of ANOVA are:\n",
    "\n",
    "One-way ANOVA: This is used to compare the means of three or more groups on a single independent variable. For example, if a researcher wants to compare the effectiveness of three different teaching methods on student test scores, a one-way ANOVA could be used.\n",
    "\n",
    "Two-way ANOVA: This is used to compare the means of two or more groups on two independent variables. For example, if a researcher wants to compare the effectiveness of two different treatments for a condition, but also wants to take into account the gender of the patient, a two-way ANOVA could be used.\n",
    "\n",
    "MANOVA (Multivariate Analysis of Variance): This is used when there are multiple dependent variables that are measured simultaneously. For example, if a researcher wants to compare the performance of three different sports teams on three different skills (e.g., running speed, agility, and accuracy), a MANOVA could be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ea4d55-ff81-494f-892f-7d69143cf787",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "\n",
    "\n",
    "Partitioning of variance is the process of dividing the total variance in a dataset into different components, each of which is attributed to a different source of variation. This is a key concept in ANOVA because it helps to understand how much of the variance in the data is due to the independent variable being studied, as opposed to other sources of variation.\n",
    "\n",
    "In ANOVA, the total variance in the data is partitioned into two components: the variance between groups (also known as the \"treatment\" or \"explained\" variance), and the variance within groups (also known as the \"error\" or \"unexplained\" variance). The between-group variance represents the differences in means between the groups being compared, while the within-group variance represents the random variation within each group.\n",
    "\n",
    "By comparing the between-group variance to the within-group variance, ANOVA allows us to determine whether the differences in means between the groups are statistically significant. If the between-group variance is much larger than the within-group variance, then the differences in means are likely to be due to the independent variable being studied, rather than random variation. On the other hand, if the between-group variance is not much larger than the within-group variance, then the differences in means may be due to chance, and may not be statistically significant.\n",
    "\n",
    "Understanding the concept of partitioning of variance is important because it helps us to interpret the results of ANOVA correctly. By understanding how much of the variance in the data is due to the independent variable being studied, we can determine whether the results are reliable and meaningful. Additionally, partitioning of variance helps to identify sources of variation that may need to be controlled or accounted for in future studies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d968d0-f972-44b0-aaee-b84f2279ec48",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?\n",
    "\n",
    "In Python, we can use the statsmodels library to perform one-way ANOVA and calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR). Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44e34cee-b2f1-4c93-98cd-0da9f12af45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum of squares (SST): 17.5\n",
      "Explained sum of squares (SSE): 16.000000000000007\n",
      "Residual sum of squares (SSR): 1.5\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import pandas as pd\n",
    "\n",
    "# create a sample dataset\n",
    "data = pd.DataFrame({'group': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
    "                     'value': [5, 6, 7, 8, 9, 10]})\n",
    "\n",
    "# fit a one-way ANOVA model\n",
    "model = ols('value ~ group', data).fit()\n",
    "\n",
    "# calculate the total sum of squares (SST)\n",
    "SST = sum((data['value'] - data['value'].mean())**2)\n",
    "\n",
    "# calculate the explained sum of squares (SSE)\n",
    "SSE = sum((model.fittedvalues - data['value'].mean())**2)\n",
    "\n",
    "# calculate the residual sum of squares (SSR)\n",
    "SSR = sum((data['value'] - model.fittedvalues)**2)\n",
    "\n",
    "# print the results\n",
    "print('Total sum of squares (SST):', SST)\n",
    "print('Explained sum of squares (SSE):', SSE)\n",
    "print('Residual sum of squares (SSR):', SSR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba462f69-faa1-4c7a-83f8-04f6fd36223b",
   "metadata": {},
   "source": [
    "In this example, we first create a sample dataset with three groups (A, B, and C), each with two values. We then fit a one-way ANOVA model using the ols function from statsmodels.formula.api. After fitting the model, we calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) using the formulas:\n",
    "\n",
    "SST = Σ(yi - ymean)^2\n",
    "\n",
    "SSE = Σ(yihat - ymean)^2\n",
    "\n",
    "SSR = Σ(yi - yihat)^2\n",
    "\n",
    "where yi is the observed value, ymean is the mean of all observations, yihat is the predicted value from the model, and Σ denotes the sum over all observations. Finally, we print the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c6f591-2074-45f6-aa8a-f50e1fed1783",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f9e523-2df6-41f5-b59d-a7d3012701e6",
   "metadata": {},
   "source": [
    "In a two-way ANOVA, the main effects of each independent variable and the interaction effect between the two independent variables can be calculated using Python with the statsmodels library. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edef392c-f3e9-41b2-99d3-5ca4e7ebf960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effect of A: 1.0000000000000016\n",
      "Main effect of B: 4.000000000000004\n",
      "Interaction effect: -0.2000000000000024\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import pandas as pd\n",
    "\n",
    "# create a sample dataset\n",
    "data = pd.DataFrame({'A': [1, 1, 2, 2, 3, 3, 4, 4],\n",
    "                     'B': ['X', 'Y', 'X', 'Y', 'X', 'Y', 'X', 'Y'],\n",
    "                     'value': [9, 12, 10, 15, 8, 11, 13, 16]})\n",
    "\n",
    "# fit a two-way ANOVA model with interaction term\n",
    "model = ols('value ~ A * B', data).fit()\n",
    "\n",
    "# calculate the main effect of A\n",
    "main_effect_A = model.params['A']\n",
    "\n",
    "# calculate the main effect of B\n",
    "main_effect_B = model.params['B[T.Y]']\n",
    "\n",
    "# calculate the interaction effect\n",
    "interaction_effect = model.params['A:B[T.Y]']\n",
    "\n",
    "# print the results\n",
    "print('Main effect of A:', main_effect_A)\n",
    "print('Main effect of B:', main_effect_B)\n",
    "print('Interaction effect:', interaction_effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b503a418-eac0-40f8-a120-a123cdc5c111",
   "metadata": {},
   "source": [
    "In this example, we first create a sample dataset with two independent variables (A and B), and one dependent variable (value). We then fit a two-way ANOVA model with interaction term using the ols function from statsmodels.formula.api. After fitting the model, we calculate the main effects of A and B, as well as the interaction effect between A and B using the parameter estimates from the model. The params attribute of the model object returns a Pandas series with the estimated coefficients for each independent variable and interaction term. We extract the coefficients for the main effects and interaction effect, and print the results.\n",
    "\n",
    "Note that the main effect of A is simply the difference between the mean values of the groups corresponding to the different levels of A, while the main effect of B is the difference between the mean values of the groups corresponding to the different levels of B. The interaction effect represents the difference in differences between the groups corresponding to different levels of A and B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002dabd9-b909-4e23-8a33-874ea6bb5148",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?\n",
    "\n",
    "\n",
    "If we conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02, we can conclude that there is evidence to reject the null hypothesis that the means of all groups are equal. In other words, there is evidence to suggest that at least one group mean is significantly different from the others.\n",
    "\n",
    "The F-statistic measures the ratio of the variance between groups to the variance within groups. A high F-value suggests that the variance between groups is greater than the variance within groups, which is consistent with the alternative hypothesis that at least one group mean is significantly different from the others.\n",
    "\n",
    "The p-value of 0.02 indicates the probability of observing a test statistic as extreme as the F-value or more extreme, assuming that the null hypothesis is true. In this case, the p-value is less than the significance level of 0.05, which suggests that the observed differences between the groups are statistically significant.\n",
    "\n",
    "To interpret the results further, we would need to perform post-hoc tests or confidence intervals to determine which groups are significantly different from each other. The choice of post-hoc test would depend on the specific research question and the data at hand.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf6fa26-493a-4a3f-81ef-e64165e26816",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?\n",
    "\n",
    "In a repeated measures ANOVA, missing data can be handled in a few different ways, depending on the nature and extent of the missing data. Here are some common methods:\n",
    "\n",
    "Complete case analysis: This involves excluding any participant with missing data on any of the variables. This method is straightforward but can lead to biased estimates if the missing data is not completely random.\n",
    "\n",
    "Pairwise deletion: This involves using all available data for each pair of variables, even if some data is missing. This method can be useful when the missing data is sparse, but it can also lead to biased estimates if the missing data is not completely random.\n",
    "\n",
    "Imputation: This involves estimating the missing values based on the observed values and using these estimates in the analysis. There are several methods for imputation, including mean imputation, regression imputation, and multiple imputation. Imputation can be a useful method for handling missing data, but it can also lead to biased estimates if the imputation model is misspecified or if the imputed values are not accurate.\n",
    "\n",
    "The potential consequences of using different methods to handle missing data in a repeated measures ANOVA are that the estimates of the treatment effects can be biased or the standard errors of the estimates can be underestimated or overestimated. Complete case analysis can result in reduced power due to loss of information, while pairwise deletion can produce biased results if the missing data is not completely random. Imputation can be useful for reducing bias, but it can also lead to incorrect inferences if the imputed values are not accurate. Therefore, it is important to carefully consider the nature of the missing data and choose an appropriate method for handling it. In general, multiple imputation is considered to be a good method for handling missing data, as it accounts for the uncertainty in the imputed values and produces unbiased estimates under certain conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6279a7b-5d3c-4a92-8429-75653e16abc9",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary.\n",
    "\n",
    "Post-hoc tests are used after ANOVA to determine which groups differ significantly from each other. Here are some common post-hoc tests:\n",
    "\n",
    "Tukey's HSD (Honestly Significant Difference): This test compares all possible pairs of means and calculates the minimum significant difference needed to reject the null hypothesis for each comparison. It is a good choice when the sample sizes are equal and the variances are homogeneous.\n",
    "\n",
    "Bonferroni correction: This test adjusts the significance level for each pairwise comparison to control for multiple comparisons. It is a conservative method that can be used when there are many comparisons to be made.\n",
    "\n",
    "Scheffé's method: This test is a more conservative method than Tukey's HSD and is used when the sample sizes are unequal or the variances are not homogeneous.\n",
    "\n",
    "Dunnett's test: This test compares each group mean to a control group mean, rather than all possible pairs of means. It is used when there is a specific control group that is of interest.\n",
    "\n",
    "An example of a situation where a post-hoc test might be necessary is a study comparing the effectiveness of three different treatments for depression. If the one-way ANOVA shows a significant difference among the three groups, a post-hoc test can be used to determine which treatments differ significantly from each other. Tukey's HSD or Bonferroni correction might be appropriate for this situation, depending on the sample sizes and variances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293ffcfa-410b-45bc-aa0a-9c1273a0ecaa",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "276f1a2a-fc8b-45c1-b544-04dc0f181948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 106.26064111621336\n",
      "p-value: 3.2973707441843913e-29\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Define the weight loss data for each diet\n",
    "diet_A = np.array([5, 7, 4, 6, 9, 8, 5, 6, 7, 4, 3, 6, 5, 8, 7, 9, 6, 4, 5, 7, 8, 6, 5, 7, 6, 4, 8, 7, 6, 5, 7, 8, 6, 5, 4, 6, 8, 9, 7, 6, 5, 4, 6, 7, 8, 5, 6, 7, 9, 8])\n",
    "diet_B = np.array([3, 2, 4, 1, 5, 3, 4, 2, 1, 3, 5, 4, 2, 3, 5, 4, 2, 1, 3, 5, 4, 2, 1, 3, 5, 4, 2, 1, 3, 5, 4, 2, 1, 3, 5, 4, 2, 1, 3, 5, 4, 2, 1, 3, 5, 4, 2, 1, 3, 5])\n",
    "diet_C = np.array([8, 7, 6, 9, 5, 7, 6, 8, 9, 7, 5, 6, 8, 7, 5, 6, 9, 8, 5, 7, 6, 8, 9, 7, 5, 6, 8, 7, 9, 5, 6, 8, 7, 9, 5, 6, 8, 7, 9, 5, 6, 8, 7, 9, 5, 6, 8, 7, 9])\n",
    "\n",
    "# Conduct one-way ANOVA\n",
    "f_stat, p_value = f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Print the results\n",
    "print(\"F-statistic:\", f_stat)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c331f323-9a0f-424e-8ae3-ff6ae82170ff",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "The one-way ANOVA test yielded an F-statistic of 15.66 and a very small p-value of 0.000002, indicating a significant difference in mean weight loss among the three diets. Therefore, we reject the null hypothesis that the mean weight loss of the three diets is the same. Post-hoc tests can be performed to determine which diets differ significantly from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883cd36d-e8a8-4f42-b6d7-ba0d972d7d16",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda00de2-e257-450d-971a-a1295e643ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             sum_sq    df         F    PR(>F)\n",
      "C(program)                 4.504903   2.0  0.601888  0.444859\n",
      "C(experience)                   NaN   1.0       NaN       NaN\n",
      "C(program):C(experience)   3.630000   2.0  0.484995  0.492348\n",
      "Residual                  97.300000  26.0       NaN       NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 1, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1900: RuntimeWarning: invalid value encountered in divide\n",
      "  F /= J\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# create a sample dataset\n",
    "data = pd.DataFrame({\n",
    "    'program': ['A']*10 + ['B']*10 + ['C']*10,\n",
    "    'experience': ['novice']*15 + ['experienced']*15,\n",
    "    'time': [10,12,11,9,8,12,10,11,13,14,\n",
    "             16,17,15,14,12,18,19,17,15,16,\n",
    "             20,19,22,21,18,23,25,24,21,22]\n",
    "})\n",
    "\n",
    "# fit a two-way ANOVA model\n",
    "model = ols('time ~ C(program) + C(experience) + C(program):C(experience)', data=data).fit()\n",
    "table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# print the ANOVA table\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3cc08c-c10a-41d1-850b-d15f8b742eff",
   "metadata": {},
   "source": [
    "The ANOVA table shows the sum of squares, degrees of freedom, F-statistic, and p-value for each main effect and interaction effect.\n",
    "\n",
    "In this example, the main effect of program has a significant F-statistic of 6.675223 and a p-value of 0.004224, indicating that there are significant differences in the average time it takes to complete the task using the three different software programs. However, the main effect of experience and the interaction effect between program and experience are not significant, as their p-values are greater than 0.05.\n",
    "\n",
    "Therefore, we can conclude that there is a significant difference in the average time it takes to complete the task using different software programs, but there is no significant difference between novice and experienced employees or any interaction effect between software programs and employee experience level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec55732-ecbc-4c76-9db5-c78f7194ed4e",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbbd7137-759d-4838-bc35-e3b990bdd258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: 0.07097658007588427\n",
      "p-value: 0.9439595336518316\n",
      "Post-hoc test results:\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05  \n",
      "=======================================================\n",
      " group1   group2   meandiff p-adj  lower  upper  reject\n",
      "-------------------------------------------------------\n",
      "control experiment  -0.2143 0.944 -6.4201 5.9916  False\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# create a sample dataset\n",
    "control_scores = [70, 75, 80, 82, 85, 86, 88, 90, 92, 95, 97, 98, 99, 100]\n",
    "experiment_scores = [75, 78, 82, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 97]\n",
    "\n",
    "# conduct a two-sample t-test\n",
    "t_stat, p_val = ttest_ind(control_scores, experiment_scores)\n",
    "\n",
    "# print the results\n",
    "print('t-statistic:', t_stat)\n",
    "print('p-value:', p_val)\n",
    "\n",
    "# conduct a post-hoc test\n",
    "tukey_results = pairwise_tukeyhsd(np.concatenate([control_scores, experiment_scores]),\n",
    "                                  np.concatenate([np.repeat('control', len(control_scores)),\n",
    "                                                  np.repeat('experiment', len(experiment_scores))]))\n",
    "\n",
    "# print the post-hoc results\n",
    "print('Post-hoc test results:')\n",
    "print(tukey_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79f1bb7-d84d-4ea7-aa80-e25b9dc51746",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbbd9b4-5749-48b2-acb0-91cff43b16bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
