{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbe4fca8-873e-4979-8b04-42fd1c02ad87",
   "metadata": {},
   "source": [
    "Q1. Write a Python code to implement the KNN classifier algorithm on load_iris dataset in\n",
    "sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e38b24c5-cb81-40fc-b33f-c40ff4449a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a KNN classifier with k=3\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the KNN classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41390d76-ec73-4a50-ba86-eea6fec92735",
   "metadata": {},
   "source": [
    "Q2. Write a Python code to implement the KNN regressor algorithm on load_boston dataset in\n",
    "sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e50f9e0-4c6a-4205-903c-2e9f5c40793d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/datasets/_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 25.860125490196076\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the Boston housing dataset\n",
    "boston = fetch_openml(name='boston', version=1)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a KNN regressor object\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = knn_regressor.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307be44e-6e12-4c3e-b84d-d79780ce00d8",
   "metadata": {},
   "source": [
    "Q3. Write a Python code snippet to find the optimal value of K for the KNN classifier algorithm using\n",
    "cross-validation on load_iris dataset in sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7d9e00e-be5b-4eb5-88b9-3e982920a2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal K: 3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a list of K values to evaluate\n",
    "k_values = list(range(1, 21))\n",
    "\n",
    "# Initialize lists to store mean cross-validation scores\n",
    "cv_scores = []\n",
    "\n",
    "# Perform cross-validation for each K value\n",
    "for k in k_values:\n",
    "    # Create a KNN classifier object\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # Perform cross-validation and calculate mean score\n",
    "    scores = cross_val_score(knn_classifier, X_train, y_train, cv=5)\n",
    "    mean_score = scores.mean()\n",
    "    \n",
    "    # Append mean score to the list\n",
    "    cv_scores.append(mean_score)\n",
    "\n",
    "# Find the optimal value of K with the highest cross-validation score\n",
    "optimal_k = k_values[cv_scores.index(max(cv_scores))]\n",
    "\n",
    "print(\"Optimal K:\", optimal_k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a80a43-918f-423a-8312-d3e284d12ea5",
   "metadata": {},
   "source": [
    "Q4. Implement the KNN regressor algorithm with feature scaling on load_boston dataset in\n",
    "sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afaac0bf-05f1-4fc7-8d75-f5757efa74b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 20.60552941176471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/datasets/_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the Boston housing dataset\n",
    "boston = fetch_openml(name='boston', version=1)\n",
    "\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a KNN regressor object\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# Fit the model to the scaled training data\n",
    "knn_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the scaled test data\n",
    "y_pred = knn_regressor.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c32604-7e60-42e4-8d1c-5731f8f1cc41",
   "metadata": {},
   "source": [
    "Q5. Write a Python code snippet to implement the KNN classifier algorithm with weighted voting on\n",
    "load_iris dataset in sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "543ffb6a-4fb1-46b1-96d3-c3f95e17f91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a KNN classifier object with weighted voting\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "# Print the predicted labels\n",
    "print(\"Predicted labels:\", y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3177a6-a4c8-4dea-afeb-cf18698412d1",
   "metadata": {},
   "source": [
    "Q6. Implement a function to standardise the features before applying KNN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c07a7498-6999-4954-843e-3d8c365e7553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def standardize_features(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Standardize the features using the StandardScaler.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train: Training data features\n",
    "    - X_test: Test data features\n",
    "\n",
    "    Returns:\n",
    "    - X_train_scaled: Standardized training data features\n",
    "    - X_test_scaled: Standardized test data features\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51941196-aa61-4339-932e-85be76a858c7",
   "metadata": {},
   "source": [
    "Q7. Write a Python function to calculate the euclidean distance between two points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae9d70c8-e290-4aa2-8659-233798dd5872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between two points.\n",
    "\n",
    "    Parameters:\n",
    "    - point1: First point as a list or tuple of coordinates (x1, y1, z1, ...)\n",
    "    - point2: Second point as a list or tuple of coordinates (x2, y2, z2, ...)\n",
    "\n",
    "    Returns:\n",
    "    - distance: Euclidean distance between the two points\n",
    "    \"\"\"\n",
    "    distance = math.sqrt(sum((a - b) ** 2 for a, b in zip(point1, point2)))\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80895b57-beae-45c9-b124-14737c43dcf6",
   "metadata": {},
   "source": [
    "Q8. Write a Python function to calculate the manhattan distance between two points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32cbfa60-6938-4d08-a437-c475b61e1aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculate the Manhattan distance between two points.\n",
    "\n",
    "    Parameters:\n",
    "    - point1: First point as a list or tuple of coordinates (x1, y1, z1, ...)\n",
    "    - point2: Second point as a list or tuple of coordinates (x2, y2, z2, ...)\n",
    "\n",
    "    Returns:\n",
    "    - distance: Manhattan distance between the two points\n",
    "    \"\"\"\n",
    "    distance = sum(abs(a - b) for a, b in zip(point1, point2))\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd15d01-3dff-4823-9eb7-25e7fd69006d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
